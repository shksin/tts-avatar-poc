{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create ACS Index and Azure SQL Database for Avatar Demo\n",
        "Use this notebook to create an Azure Cognitive Search Index and an Azure SQL Database and populate demo content for the Avatar outdoor shop application.  \n",
        "\n",
        "Ensure that you have the the Microsoft ODBC driver for SQL Server installed. Here are the instructions for Linux based systems:  \n",
        "https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline#18\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1700038369590
        }
      },
      "outputs": [],
      "source": [
        "# Install the required libraries\n",
        "%pip install azure-search-documents==11.4.0b6 openai==0.28.1 tenacity pyodbc\n",
        "\n",
        "# Install pandas\n",
        "%pip install pandas\n",
        "\n",
        "#Insrall pyplot\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1700038372029
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json  \n",
        "import pandas as pd\n",
        "\n",
        "import pyodbc\n",
        "import requests\n",
        "import inspect\n",
        "\n",
        "import openai  \n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
        "from azure.core.credentials import AzureKeyCredential  \n",
        "from azure.search.documents import SearchClient  \n",
        "from azure.search.documents.indexes import SearchIndexClient  \n",
        "from azure.search.documents.models import Vector  \n",
        "from azure.search.documents.indexes.models import (  \n",
        "    SearchIndex,  \n",
        "    SearchField,  \n",
        "    SearchFieldDataType,  \n",
        "    SimpleField,  \n",
        "    SearchableField,  \n",
        "    SearchIndex,  \n",
        "    SemanticConfiguration,  \n",
        "    PrioritizedFields,  \n",
        "    SemanticField,  \n",
        "    SearchField,  \n",
        "    SemanticSettings,  \n",
        "    VectorSearch,  \n",
        "    VectorSearchAlgorithmConfiguration,  \n",
        ")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "You need to have the following settings for your Azure resources defined in the `local.settings.json` file in the __api__ subfolder to populate the demo content for the outdoor app:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1700038375485
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load JSON file\n",
        "with open('./api/local.settings.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Azure Cognitive Search\n",
        "service_endpoint = data[\"Values\"][\"AZURE_SEARCH_ENDPOINT\"]\n",
        "key = data[\"Values\"][\"AZURE_SEARCH_API_KEY\"]\n",
        "index_name = data[\"Values\"][\"AZURE_SEARCH_INDEX\"]\n",
        "\n",
        "# Blob SAS URL for Azure Storage Account\n",
        "blob_sas_url = data[\"Values\"][\"BLOB_SAS_URL\"]\n",
        "\n",
        "# Azure OpenAI\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_key = data[\"Values\"][\"AZURE_OPENAI_API_KEY\"]\n",
        "openai.api_base = data[\"Values\"][\"AZURE_OPENAI_ENDPOINT\"]\n",
        "openai.api_version = data[\"Values\"][\"AZURE_OPENAI_API_VERSION\"]\n",
        "AOAI_embeddings_deployment = data[\"Values\"][\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]\n",
        "\n",
        "# Azure SQL Database\n",
        "sql_db_server = data[\"Values\"][\"SQL_DB_SERVER\"]\n",
        "sql_db_user = data[\"Values\"][\"SQL_DB_USER\"]\n",
        "sql_db_password = data[\"Values\"][\"SQL_DB_PASSWORD\"]\n",
        "sql_db_name = data[\"Values\"][\"SQL_DB_NAME\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Cognitive Search Index\n",
        "First, we create a new Index with demo data to the Cognitive Search service that you have deployed manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873170121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "credential = AzureKeyCredential(key)\n",
        "\n",
        "df = pd.read_csv('data/products_cs_index.csv', dtype={'id': str})\n",
        "display(df.head())\n",
        "input_data = df.to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1699873170374
        }
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
        "def generate_embeddings(text):\n",
        "    response = openai.Embedding.create(\n",
        "        input=text, engine=AOAI_embeddings_deployment)\n",
        "    embeddings = response['data'][0]['embedding']\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1699873171802
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Generate embeddings for title and content fields\n",
        "for item in input_data:\n",
        "    tagline = item['tagline']\n",
        "    description = item['description']\n",
        "    tagline_embeddings = generate_embeddings(tagline)\n",
        "    description_embeddings = generate_embeddings(description)\n",
        "    item['tagline_vector'] = tagline_embeddings\n",
        "    item['description_vector'] = description_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1699873171984
        }
      },
      "outputs": [],
      "source": [
        "# Output embeddings to docVectors.json file\n",
        "with open(\"./data/product-catalog-vectors.json\", \"w\") as f:\n",
        "    json.dump(input_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873172252
        }
      },
      "outputs": [],
      "source": [
        "# Delete ACS index if it exists\n",
        "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
        "\n",
        "try:\n",
        "    if index_client.get_index(index_name):\n",
        "        print('Deleting existing index...')\n",
        "        index_client.delete_index(index_name)\n",
        "\n",
        "except:\n",
        "    print('Index does not exist. No need to delete it.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873172892
        }
      },
      "outputs": [],
      "source": [
        "# Create a search index\n",
        "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
        "\n",
        "fields = [\n",
        "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
        "    SearchableField(name=\"name\", type=SearchFieldDataType.String),\n",
        "    SearchableField(name=\"tagline\", type=SearchFieldDataType.String),\n",
        "    SearchableField(name=\"description\", type=SearchFieldDataType.String),\n",
        "    SimpleField(name=\"original_price\", type=SearchFieldDataType.Double),\n",
        "    SimpleField(name=\"special_offer\", type=SearchFieldDataType.Double),\n",
        "    SearchableField(name=\"category\", type=SearchFieldDataType.String, filterable=True),\n",
        "    SearchField(name=\"tagline_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
        "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
        "    SearchField(name=\"description_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
        "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
        "    SimpleField(name=\"product_image_file\", type=SearchFieldDataType.String),\n",
        "]\n",
        "\n",
        "vector_search = VectorSearch(\n",
        "    algorithm_configurations=[\n",
        "        VectorSearchAlgorithmConfiguration(\n",
        "            name=\"my-vector-config\",\n",
        "            kind=\"hnsw\",\n",
        "            hnsw_parameters={\n",
        "                \"m\": 4,\n",
        "                \"efConstruction\": 400,\n",
        "                \"efSearch\": 500,\n",
        "                \"metric\": \"cosine\"\n",
        "            }\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "semantic_config = SemanticConfiguration(\n",
        "    name=\"my-semantic-config\",\n",
        "    prioritized_fields=PrioritizedFields(\n",
        "        title_field=SemanticField(field_name=\"tagline\"),\n",
        "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
        "        prioritized_content_fields=[SemanticField(field_name=\"description\")]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create the semantic settings with the configuration\n",
        "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
        "\n",
        "# Create the search index with the semantic settings\n",
        "index = SearchIndex(name=index_name, fields=fields,\n",
        "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
        "result = index_client.create_or_update_index(index)\n",
        "print(f' {result.name} created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873173454
        }
      },
      "outputs": [],
      "source": [
        "# Upload documents to the index\n",
        "with open(\"./data/product-catalog-vectors.json\", 'r') as file:  \n",
        "    documents = json.load(file)  \n",
        "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
        "result = search_client.upload_documents(documents)  \n",
        "print(f\"Uploaded {len(documents)} documents\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Perform Test Queries\n",
        "We are performing a few test queries against the Cognitive Search index. If successful, it should display outdoor product information and images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1699873173581
        }
      },
      "outputs": [],
      "source": [
        "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
        "fields_of_interest = [\"id\", \"name\", \"tagline\", \"description\", \"original_price\", \"special_offer\", \"category\", \"product_image_file\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873175487
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from matplotlib import pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "def display_image_from_blob(image_file):\n",
        "   \n",
        "  # Append the image name to the SAS URL\n",
        "  image_url = blob_sas_url.split(\"?\")[0] + f\"/{image_file}?\" + blob_sas_url.split(\"?\")[1]\n",
        "\n",
        "  # Get the image content\n",
        "  response = requests.get(image_url)\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Open the image and display it\n",
        "      img = plt.imread(BytesIO(response.content))\n",
        "      plt.imshow(img)\n",
        "      plt.axis('off') # No axes for this plot\n",
        "      plt.show()\n",
        "  else:\n",
        "      print(f\"Failed to retrieve image. HTTP Status code: {response.status_code}\")\n",
        "\n",
        "def print_results(results):  \n",
        "  for result in results:  \n",
        "    print(f\"Score: {result['@search.score']}\")\n",
        "    print(f\"Name: {result['name']}\")  \n",
        "    print(f\"Category: {result['category']}\")\n",
        "    print(f\"Tagline: {result['tagline']}\")\n",
        "    print(f\"Description: {result['description'][:50]}\")\n",
        "    print(f\"Original price: {result['original_price']}\")\n",
        "    print(f\"Special offer: {result['special_offer']}\")\n",
        "    print(f\"Image file: {result['product_image_file']}\\n\")\n",
        "    display_image_from_blob(result['product_image_file'])\n",
        "\n",
        "\n",
        "# Pure Vector Search with Filter\n",
        "query = \"tent for two people\"  \n",
        " \n",
        "results = search_client.search(  \n",
        "    search_text=None,  \n",
        "    vector=generate_embeddings(query), top_k=3,  \n",
        "    vector_fields=\"description_vector\",\n",
        "    filter=\"category eq 'outdoor'\",\n",
        "    select= fields_of_interest\n",
        ")  \n",
        "  \n",
        "print_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Azure SQL Database\n",
        "Now we are creating a small Azure SQL Database with customer, products and order data using the SQL Server that you have deployed manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1699873175635
        }
      },
      "outputs": [],
      "source": [
        "# Connection Strings\n",
        "server_connection_string = f\"Driver={{ODBC Driver 18 for SQL Server}};Server=tcp:{sql_db_server},1433;Uid={sql_db_user};Pwd={sql_db_password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
        "database_connection_string = server_connection_string + f\"Database={sql_db_name};\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1699873175773
        }
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "customers = [\n",
        "    {\"name\": \"John Doe\", \"account_id\": 1000, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Jane Smith\", \"account_id\": 1001, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Alice Johnson\", \"account_id\": 1002, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Bob Wilson\", \"account_id\": 1003, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Charlie Brown\", \"account_id\": 1004, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Eve Adams\", \"account_id\": 1005, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Frank Castle\", \"account_id\": 1006, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Grace Lee\", \"account_id\": 1007, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Hannah Montan\", \"account_id\": 1008, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Ian Somerhalder\", \"account_id\": 1009, \"loyalty_points\" : random.randint(400, 800)},\n",
        "    {\"name\": \"Peter Mick\", \"account_id\": 1010, \"loyalty_points\" : random.randint(400, 800)},\n",
        "]\n",
        "\n",
        "products = [\n",
        "    {\"id\": 1000, \"name\": \"Elysian Voyager\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1001, \"name\": \"Terra Roamer\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1002, \"name\": \"Cardinal Pathfinder\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1003, \"name\": \"Slumber Drifter\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1004, \"name\": \"Blaze Adventurer\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1005, \"name\": \"BiteShield Pro\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1006, \"name\": \"Feast Frontier\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1007, \"name\": \"Summit Stride\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1008, \"name\": \"Rugged Ranger\",\"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1100, \"name\": \"Match Master\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1101, \"name\": \"Court Queen\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1102, \"name\": \"Junior Ace\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1103, \"name\": \"ServeMaster Pro\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1104, \"name\": \"Court Commander\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1105, \"name\": \"StringMaster Elite\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1106, \"name\": \"Court Conqueror\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1107, \"name\": \"AceMaster 3000\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1108, \"name\": \"Ace Attire\", \"stock\": random.randint(0,50)},\n",
        "    {\"id\": 1109, \"name\": \"Serve & Style\", \"stock\": random.randint(0,50)},\n",
        "]\n",
        "orders = [\n",
        "    {\"order_id\": 1000, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1000},\n",
        "    {\"order_id\": 1001, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
        "    {\"order_id\": 1002, \"product_id\": 1002, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
        "    {\"order_id\": 1003, \"product_id\": 1003, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
        "    {\"order_id\": 1004, \"product_id\": 1004, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
        "    {\"order_id\": 1005, \"product_id\": 1005, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
        "    {\"order_id\": 1006, \"product_id\": 1006, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
        "    {\"order_id\": 1007, \"product_id\": 1007, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
        "    {\"order_id\": 1008, \"product_id\": 1008, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
        "    {\"order_id\": 1010, \"product_id\": 1000, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1009},\n",
        "    {\"order_id\": 1012, \"product_id\": 1101, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
        "    {\"order_id\": 1013, \"product_id\": 1102, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
        "    {\"order_id\": 1014, \"product_id\": 1103, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
        "    {\"order_id\": 1015, \"product_id\": 1104, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
        "    {\"order_id\": 1016, \"product_id\": 1105, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
        "    {\"order_id\": 1017, \"product_id\": 1106, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
        "    {\"order_id\": 1018, \"product_id\": 1107, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
        "    {\"order_id\": 1019, \"product_id\": 1108, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873175920
        }
      },
      "outputs": [],
      "source": [
        "# Test connection to the SQL Server\n",
        "\n",
        "try:\n",
        "    # Try to establish a connection\n",
        "    conn = pyodbc.connect(server_connection_string)\n",
        "    \n",
        "    # If connection is successful, print a message and close the connection\n",
        "    print(\"Connection to the server/database was successful!\")\n",
        "    conn.close()\n",
        "    \n",
        "except pyodbc.Error as ex:\n",
        "    # Catch any connection errors and print them\n",
        "    sqlstate = ex.args[0] if len(ex.args) > 0 else None\n",
        "    message = ex.args[1] if len(ex.args) > 1 else None\n",
        "    print(f\"Failed to connect to the server/database. SQLSTATE: {sqlstate}, Message: {message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1699873247080
        }
      },
      "outputs": [],
      "source": [
        "# SET TO TRUE ONLY TO REBUILD DATABASE BASED ON ABOVE SAMPLE DATA\n",
        "rebuild_database = True\n",
        "\n",
        "if rebuild_database:\n",
        "\n",
        "    # Connect to the server without specifying a database\n",
        "    server_conn = pyodbc.connect(server_connection_string, autocommit=True)\n",
        "    server_cursor = server_conn.cursor()\n",
        "\n",
        "    # Drop the database if it exists\n",
        "    server_cursor.execute(f\"IF EXISTS(SELECT * FROM sys.databases WHERE name='{sql_db_name}') DROP DATABASE {sql_db_name}\")\n",
        "\n",
        "    # Recreate the database\n",
        "    server_cursor.execute(f\"CREATE DATABASE {sql_db_name}\")\n",
        "    server_cursor.close()\n",
        "    server_conn.close()\n",
        "\n",
        "    # Now, connect to the newly created database\n",
        "    conn = pyodbc.connect(database_connection_string)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Ensure you're using the existing database\n",
        "    cursor.execute(f\"USE {sql_db_name}\")\n",
        "\n",
        "    # Create tables and populate them\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE Customers (\n",
        "        name VARCHAR(255),\n",
        "        account_id INT PRIMARY KEY,\n",
        "        loyalty_points INT,\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    for customer in customers:\n",
        "        cursor.execute(\"INSERT INTO Customers VALUES (?, ?, ?)\", \n",
        "                    (customer[\"name\"], customer[\"account_id\"], customer[\"loyalty_points\"]))\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE Products (\n",
        "        id INT PRIMARY KEY,\n",
        "        name VARCHAR(255),\n",
        "        stock INT\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    for product in products:\n",
        "        cursor.execute(\"INSERT INTO Products VALUES (?, ?, ?)\", \n",
        "                    (product[\"id\"], product[\"name\"], product[\"stock\"]))\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE Orders (\n",
        "        order_id INT PRIMARY KEY,\n",
        "        product_id INT,\n",
        "        days_to_delivery INT,\n",
        "        account_id INT,\n",
        "        FOREIGN KEY(product_id) REFERENCES Products(id),\n",
        "        FOREIGN KEY(account_id) REFERENCES Customers(account_id)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    for order in orders:\n",
        "        cursor.execute(\"INSERT INTO Orders VALUES (?, ?, ?, ?)\", \n",
        "                    (order[\"order_id\"], order[\"product_id\"], order[\"days_to_delivery\"], order[\"account_id\"]))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "    #Verify database tables and columns\n",
        "    def fetch_schema_info():\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT t.TABLE_NAME, c.COLUMN_NAME, c.DATA_TYPE \n",
        "            FROM INFORMATION_SCHEMA.TABLES AS t\n",
        "            JOIN INFORMATION_SCHEMA.COLUMNS AS c ON t.TABLE_NAME = c.TABLE_NAME\n",
        "            WHERE t.TABLE_SCHEMA = 'dbo'  -- assuming you're using the default schema\n",
        "            ORDER BY t.TABLE_NAME, c.ORDINAL_POSITION\n",
        "        \"\"\")\n",
        "        \n",
        "        tables = {}\n",
        "        for row in cursor.fetchall():\n",
        "            table_name = row[0]\n",
        "            column_name = row[1]\n",
        "            data_type = row[2]\n",
        "            \n",
        "            if table_name not in tables:\n",
        "                tables[table_name] = []\n",
        "            \n",
        "            tables[table_name].append(f\"{column_name} ({data_type})\")\n",
        "        \n",
        "        return tables\n",
        "\n",
        "    schema_info = fetch_schema_info()\n",
        "\n",
        "    # Print the schema info in a user-friendly format\n",
        "    for table, columns in schema_info.items():\n",
        "        print(f\"Table: {table}\")\n",
        "        for col in columns:\n",
        "            print(f\"    {col}\")\n",
        "        print()\n",
        "\n",
        "    # Close connections\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
